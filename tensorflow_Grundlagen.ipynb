{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8856fa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "scalar=tf.constant(7)\n",
    "scalar\n",
    "scalar.ndim\n",
    "vector=tf.constant([10,10])\n",
    "vector\n",
    "vector.ndim\n",
    "matrix=tf.constant([[10,7],\n",
    "                    [7,10]])\n",
    "matrix\n",
    "matrix.ndim\n",
    "another_matrix= tf.constant([[10.,7.],\n",
    "                            [7.,10.],\n",
    "                             [3.,8.]],dtype=tf.float16)\n",
    "another_matrix\n",
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073603ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=tf.constant([[[1,2,3],\n",
    "                   [4,5,6]],\n",
    "                    \n",
    "                   [[7,8,9],\n",
    "                   [10,11,12]],\n",
    "                    \n",
    "                   [[13,14,15],\n",
    "                   [16,17,18]]\n",
    "                   ])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b54c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([6, 7])>\n"
     ]
    }
   ],
   "source": [
    "tf.Variable\n",
    "variabletensor=tf.Variable([10,7])\n",
    "constanttensor=tf.constant([10,7])\n",
    "print(variabletensor)\n",
    "#print(constanttensor)\n",
    "variabletensor[0].assign(6)\n",
    "print(variabletensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1209e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.7565803  -0.06854702]\n",
      " [ 0.07595026 -1.2573844 ]\n",
      " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.7565803  -0.06854702]\n",
      " [ 0.07595026 -1.2573844 ]\n",
      " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.7565803  -0.06854702]\n",
      " [ 0.07595026 -1.2573844 ]\n",
      " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.7565803  -0.06854702]\n",
      " [ 0.07595026 -1.2573844 ]\n",
      " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1=tf.random.Generator.from_seed(42)\n",
    "random_1=random_1.normal(shape=(3,2))\n",
    "\n",
    "random_2=tf.random.Generator.from_seed(42)\n",
    "random_2=random_2.normal(shape=(3,2))\n",
    "\n",
    "random_3=tf.random.Generator.from_seed(42)\n",
    "random_3=random_3.normal(shape=(3,2))\n",
    "\n",
    "random_4=tf.random.Generator.from_seed(42)\n",
    "random_4=random_4.normal(shape=(3,2))\n",
    "\n",
    "print(random_1)\n",
    "print(random_2)\n",
    "print(random_3)\n",
    "print(random_4)\n",
    "random_1==random_2\n",
    "random_3==random_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb16f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor([10  7], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [32  7]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[10.  7.]\n",
      " [ 7.  6.]\n",
      " [ 3.  8.]], shape=(3, 2), dtype=float16)\n",
      "tf.Tensor(\n",
      "[[[12.  3.]\n",
      "  [ 7.  8.]]\n",
      "\n",
      " [[12.  5.]\n",
      "  [ 6.  7.]]\n",
      "\n",
      " [[ 6.  7.]\n",
      "  [ 4.  3.]]], shape=(3, 2, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "scalar=tf.constant(7)\n",
    "print(scalar)\n",
    "scalar.ndim\n",
    "\n",
    "vector=tf.constant([10,7])\n",
    "print(vector)\n",
    "vector.ndim\n",
    "\n",
    "matrix=tf.constant([[10,7],\n",
    "                    [32,7]])\n",
    "print(matrix)\n",
    "matrix.ndim\n",
    "\n",
    "another_matrix=tf.constant([[10.,7.],\n",
    "                           [7.,6.],\n",
    "                           [3.,8.]],dtype=tf.float16)\n",
    "print(another_matrix)\n",
    "\n",
    "tensor=tf.constant([[[12,3],\n",
    "                    [7,8]],\n",
    "                    \n",
    "                    [[12,5],\n",
    "                    [6,7]],\n",
    "                    \n",
    "                    [[6,7],\n",
    "                    [4,3]]                 \n",
    "                   ], dtype=tf.float16)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab0597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>\n",
      "tf.Tensor([10  3], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-0.7565803  -0.06854702]\n",
      " [ 0.07595026 -1.2573844 ]\n",
      " [-0.23193763 -1.8107855 ]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.23193763 -1.8107855 ]\n",
      " [ 0.09988727 -0.50998646]\n",
      " [-0.7535805  -0.57166284]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[False False]\n",
      " [False False]\n",
      " [False False]], shape=(3, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "variabletensor=tf.Variable([10,7])\n",
    "print(variabletensor)\n",
    "variabletensor[0].assign(7)\n",
    "variabletensor[1].assign(13)\n",
    "\n",
    "constanttensor=tf.constant([10,3])\n",
    "print(constanttensor)\n",
    "#constanttensor[0].assign(9) we can not apply change to tensor constant\n",
    "\n",
    "random_1=tf.random.Generator.from_seed(42)\n",
    "random_1=random_1.normal(shape=(3,2))\n",
    "\n",
    "random_2=tf.random.Generator.from_seed(43)\n",
    "random_2=random_2.normal(shape=(3,2))\n",
    "\n",
    "print(random_1)\n",
    "\n",
    "print(random_2)\n",
    "\n",
    "print(random_1==random_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af137c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.0278524   0.27974114 -0.01347923]\n",
      " [ 1.845181    0.97061104 -1.0242516 ]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.19104174 -0.9837912  -0.5921661 ]\n",
      " [-0.8555668   0.81843954  1.7230065 ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.random.Generator.from_seed(5)\n",
    "print(g1.normal(shape=[2, 3]))\n",
    "g2 = tf.random.get_global_generator()\n",
    "print(g2.normal(shape=[2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be76537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 4  3]\n",
      " [ 2  5]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 4  3]\n",
      " [ 2  5]\n",
      " [10  7]], shape=(3, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 4,  3],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled=tf.constant([[10,7],\n",
    "                         [4,3],\n",
    "                         [2,5]])\n",
    "print(not_shuffled)\n",
    "not_shuffled.ndim\n",
    "\n",
    "x=tf.random.shuffle(not_shuffled)\n",
    "print(x)# getting shuffled tensor\n",
    "\n",
    "tf.random.set_seed(42)# fixer shuffled tensor of one-- global level random set\n",
    "tf.random.shuffle(not_shuffled, seed=42)# operation level seed -- operartion level random set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efebea5b",
   "metadata": {},
   "source": [
    "#### other ways to make tensors\n",
    "###### create a tensor of zero and one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747d12a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor_zeros=tf.zeros(shape=(3,4))\n",
    "print(tensor_zeros)\n",
    "\n",
    "tensor_one=tf.ones([3,4])\n",
    "print(tensor_one)\n",
    "\n",
    "tensor_one1=tf.ones(shape=(4,5))\n",
    "print(tensor_one1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae39f02",
   "metadata": {},
   "source": [
    "##### the main different between tensorflow and array numpy is tensor can run very fast on GPU (numerical compution)\n",
    "###### we can create numpy asrray and convert it to tensor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3306200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor([ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24], shape=(24,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_A=np.arange(1,25,dtype=np.int32)\n",
    "print(numpy_A)\n",
    "\n",
    "#x=tf.constant(some_matrix)\n",
    "#y=tf.vector(vector)\n",
    "\n",
    "A=tf.constant(numpy_A,shape=(3,2,4))\n",
    "B=tf.constant(numpy_A)\n",
    "print(A)\n",
    "print(B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd67813",
   "metadata": {},
   "source": [
    "##### getting information from tensors:\n",
    "* when dealing with tensors we should be aware of the following attributes:\n",
    "* shape\n",
    "* rank\n",
    "* Axis or Diemension\n",
    "* Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae091e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(2, 3, 4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rank_4_tensor=tf.zeros(shape=[2,3,4,5])\n",
    "print(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39da5cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the element along the 0 axis: 2\n",
      " the size for our tensor tf.Tensor(120, shape=(), dtype=int32)\n",
      " the size for our tensor 120\n",
      "dimension for out tensor 4\n",
      "the type the tensor <dtype: 'float32'>\n",
      "element along the last Axis 5\n"
     ]
    }
   ],
   "source": [
    "print('the element along the 0 axis:',rank_4_tensor.shape[0])\n",
    "print(' the size for our tensor', tf.size(rank_4_tensor))\n",
    "print(' the size for our tensor', tf.size(rank_4_tensor).numpy())\n",
    "print('dimension for out tensor',rank_4_tensor.ndim)\n",
    "print('the type the tensor', rank_4_tensor.dtype)\n",
    "print('element along the last Axis',rank_4_tensor.shape[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ba0bf",
   "metadata": {},
   "source": [
    "##### indexing tensor:\n",
    "* tensors can be indexing just like python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ee3f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[1,2,3,4]\n",
    "l[:2]\n",
    "rank_4_tensor[:2,:2,:2,:2]\n",
    "rank_4_tensor[:1,:2,:3,:3]\n",
    "rank_4_tensor[:1,:,:3,:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b8a56f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimention for rank_2 tensor 2\n",
      "shape (2, 2)\n",
      "extraire the number 6 tf.Tensor([[6]], shape=(1, 1), dtype=int32)\n",
      "extraire the last element of rows and columns tf.Tensor([3 6], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_2_tensor=tf.constant([[2,3],\n",
    "                          [5,6]])\n",
    "print('dimention for rank_2 tensor',rank_2_tensor.ndim)\n",
    "print('shape',rank_2_tensor.shape)\n",
    "print('extraire the number 6',rank_2_tensor[1:2,1:2])\n",
    "print('extraire the last element of rows and columns',rank_2_tensor[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34a44c",
   "metadata": {},
   "source": [
    "#### add extra diemention to our rank 2 tensor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb3448",
   "metadata": {},
   "source": [
    "\n",
    "rank_3_tensor1=rank_2_tensor[...,tf.newaxis]\n",
    "rank_3_tensor2=rank_2_tensor[:,:,tf.newaxis]\n",
    "print(rank_3_tensor1)\n",
    "print(rank_3_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b136fc",
   "metadata": {},
   "source": [
    "##### another way to add extra diemention :\n",
    "* axis=0\n",
    "* axis=1\n",
    "* axis=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9e751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[2 3]\n",
      "  [5 6]]], shape=(1, 2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[2 3]]\n",
      "\n",
      " [[5 6]]], shape=(2, 1, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[2]\n",
      "  [3]]\n",
      "\n",
      " [[5]\n",
      "  [6]]], shape=(2, 2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "axis_0=tf.expand_dims(rank_2_tensor,axis=0)\n",
    "axis_1=tf.expand_dims(rank_2_tensor,axis=1)\n",
    "axis__1=tf.expand_dims(rank_2_tensor,axis=-1)\n",
    "print(axis_0)\n",
    "print(axis_1)\n",
    "print(axis__1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84729ebe",
   "metadata": {},
   "source": [
    "##### tensors operating:\n",
    "* we can apply some operationg to the tensor '+','-','*','/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d266cced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 20 to our tensor tf.Tensor(\n",
      "[[30 27]\n",
      " [23 24]], shape=(2, 2), dtype=int32)\n",
      "subs 2 from out tensor tf.Tensor(\n",
      "[[8 5]\n",
      " [1 2]], shape=(2, 2), dtype=int32)\n",
      "multiply 3 with our tensor tf.Tensor(\n",
      "[[30 21]\n",
      " [ 9 12]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[70 49]\n",
      " [21 28]], shape=(2, 2), dtype=int32)\n",
      "div 2 from our tensor tf.Tensor(\n",
      "[[5.  3.5]\n",
      " [1.5 2. ]], shape=(2, 2), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[13 10]\n",
      " [ 6  7]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor=tf.constant([[10,7],\n",
    "                   [3,4]])\n",
    "\n",
    "print('add 20 to our tensor',tensor+20)\n",
    "print('subs 2 from out tensor',tensor-2)\n",
    "print('multiply 3 with our tensor',tensor*3)\n",
    "print(tf.multiply(tensor,7))\n",
    "print('div 2 from our tensor',tensor/2)\n",
    "print(tf.math.add(tensor,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e351e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b70e9f7",
   "metadata": {},
   "source": [
    "##### matrix multiplication\n",
    "* in Ml matrix multiplication is one of the most common tensor operations.\n",
    "* by matrix multiplication we should be aware , that it will not works if (rowsA,columsA)(rowsB,columnsB)---->rowsA==rowsB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c72efaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tensor,tensor)\n",
    "tensor1=tf.constant([[1,2,5],\n",
    "                   [7,2,1],\n",
    "                   [3,3,3]])\n",
    "tensor2=tf.constant([[3,5],\n",
    "                    [6,7],\n",
    "                    [1,8]])\n",
    "\n",
    "tensor3=tf.constant([[3,5],\n",
    "                    [6,7],\n",
    "                    ])\n",
    "tensor1.shape\n",
    "tensor2.shape\n",
    "#tf.matmul(tensor1,tensor3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681deceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(2, 3)\n",
      "(2, 3)\n",
      "tf.Tensor(\n",
      "[[3 5 6]\n",
      " [7 8 9]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 5]\n",
      " [3 6]\n",
      " [7 3]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 66  63]\n",
      " [108 110]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# reshape a matrix\n",
    "tensor4=tf.constant([[3,5,3],\n",
    "                    [6,7,3],\n",
    "                    ])\n",
    "tensor5=tf.constant([[3,5],\n",
    "                    [6,7],\n",
    "                    [8,9]])\n",
    "print(tensor5.shape)\n",
    "print(tensor4.shape)\n",
    "tensor4_reshape=tf.reshape(tensor4,shape=(3,2)).shape\n",
    "tensor4_neue=tf.reshape(tensor4,shape=(3,2))\n",
    "tensor5_reshape=tf.reshape(tensor5,shape=(2,3)).shape\n",
    "tensor5_neue=tf.reshape(tensor5,shape=(2,3))\n",
    "print(tensor5_reshape)\n",
    "print(tensor5_neue)\n",
    "print(tensor4_neue)\n",
    "print(tf.matmul(tensor5_neue,tensor4_neue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb36ba",
   "metadata": {},
   "source": [
    "##### reshape vs transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3649b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 3 5]\n",
      " [2 4 6]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X= tf.constant([[1,2],\n",
    "                [3,4],\n",
    "               [5,6]])\n",
    "print(X)\n",
    "print(tf.transpose(X))\n",
    "print(tf.reshape(X,shape=(2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96414d4",
   "metadata": {},
   "source": [
    "######  try matrix multiplication with transpose instead of reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706edbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[35, 44],\n",
       "       [44, 56]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.transpose(X),X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc858a",
   "metadata": {},
   "source": [
    "###### the dot product\n",
    "* matrix multiplication is also referred to as the dot product\n",
    "* you can perform matrix multiplication using:\n",
    "* tf.matmul()\n",
    "* tf.tensordot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee5a1062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "Y=tf.constant([[7,8],\n",
    "              [9,10],\n",
    "              [11,12]])\n",
    "print(Y)\n",
    "tf.tensordot(tf.transpose(X),Y,axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650aaa28",
   "metadata": {},
   "source": [
    "##### changing the datatype of tensor: Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58c323cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "<dtype: 'float32'>\n",
      "<dtype: 'float16'>\n",
      "tf.Tensor([ 7. 10.], shape=(2,), dtype=float16)\n",
      "tf.Tensor([ 7 10], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "B=tf.constant([7,10])\n",
    "print(B.dtype)\n",
    "C=tf.constant([7.,10.])\n",
    "print(C.dtype)\n",
    "##changing from int32 to float16\n",
    "B=tf.cast(B,dtype=tf.float16)\n",
    "print(B.dtype)\n",
    "print(B)\n",
    "## changing the type of tensor fron float16 to int32\n",
    "E=tf.constant([7.,10.])\n",
    "E=tf.cast(E, dtype=tf.int32)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc26acf",
   "metadata": {},
   "source": [
    "#### Aggregation tensors\n",
    "* get the absolute number\n",
    "* form of aggregation\n",
    "* get the min\n",
    "* get the max\n",
    "* get the sum\n",
    "* get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ab96b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=tf.constant([-7,-10])\n",
    "tf.abs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2fbd762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[53 94 14  1 48 90 58 26 30 98 58 48 74 64 77 24 85 60 89 85 30 86 59 83\n",
      "  1 99 81 40 70 88  2 75  9 79 96 62 42 32  0 79 95 72 77 33 38 63 65 98\n",
      " 96 65], shape=(50,), dtype=int32)\n",
      "the size tf.Tensor(50, shape=(), dtype=int32)\n",
      "1\n",
      "(50,)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(99, shape=(), dtype=int32)\n",
      "tf.Tensor(59, shape=(), dtype=int32)\n",
      "tf.Tensor(2991, shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'std_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8805f08134ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'std_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "E=tf.constant(np.random.randint(0,100,size=50))\n",
    "print(E)\n",
    "print('the size',tf.size(E))\n",
    "print(E.ndim)\n",
    "print(E.shape)\n",
    "# find the min\n",
    "min_tensor=tf.reduce_min(E)\n",
    "max_tensor=tf.reduce_max(E)\n",
    "mean_tensor=tf.reduce_mean(E)\n",
    "sum_tensor=tf.reduce_sum(E)\n",
    "print(min_tensor)\n",
    "print(max_tensor)\n",
    "print(mean_tensor)\n",
    "print(sum_tensor)\n",
    "print(std_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb588ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance ,std\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "E=tf.constant(np.random.randint(0,100,size=50))\n",
    "# variance :\n",
    "var_tensor=tfp.stats.variance(E)\n",
    "var_ten=tf.math.reduce_variance(tf.cast(E,dtype=tf.float32))\n",
    "print(var_tensor)\n",
    "print(var_ten)\n",
    "\n",
    "# standard deviation:\n",
    "\n",
    "std_tensor=tf.math.reduce_std(tf.cast(E,dtype=tf.float32))\n",
    "print(std_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a502a",
   "metadata": {},
   "source": [
    "#### find the positional maximum and minimum:\n",
    "##### create a new tensor for finding positionla min and max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "F=tf.random.uniform(shape=[50])\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f27614b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ee8e78d1b0c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# find the positiona max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# position of max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# index of largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# max value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#max value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# find the positiona max\n",
    "print(tf.argmax(F))# position of max\n",
    "# index of largest value\n",
    "print(F[tf.argmax(F)])# max value\n",
    "print(tf.reduce_max(F)) #max value\n",
    "tf.reduce_max(F)==F[tf.argmax(F)]\n",
    "\n",
    "\n",
    "### find the min value:\n",
    "print(tf.argmin(F))# position min value\n",
    "print(F[tf.argmin(F)])# the min value\n",
    "print(tf.reduce_min(F))\n",
    "assert F[tf.argmin(F)]== tf.reduce_min(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8d00d",
   "metadata": {},
   "source": [
    "###### squeezing a tensor(removing all signle dimention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71d72e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       " array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "        0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "        0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "        0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "        0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "        0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "        0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "        0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "        0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "        0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "       dtype=float32)>,\n",
       " TensorShape([50]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "G=tf.constant(tf.random.uniform(shape=[50]),shape=(1,1,1,1,50))\n",
    "G\n",
    "\n",
    "# squezing the tensor\n",
    "G_squeezed=tf.squeeze(G)\n",
    "G_squeezed,G_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbcae5",
   "metadata": {},
   "source": [
    "### numerical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77cf80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[b'm' b'b' b'b' b'b']\n",
      " [b'b' b'm' b'b' b'b']\n",
      " [b'b' b'b' b'm' b'b']\n",
      " [b'b' b'b' b'b' b'm']], shape=(4, 4), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "some_list=[0,1,2,3]\n",
    "one_hot_encode=tf.one_hot(some_list,depth=4)\n",
    "print(one_hot_encode)\n",
    "\n",
    "one_hot_encode2=tf.one_hot(some_list,depth=4,on_value='m',off_value='b')\n",
    "print(one_hot_encode2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66777438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### squaring, log, square root\n",
    "H= tf.range(1,10)\n",
    "H\n",
    "tf.square(H)\n",
    "tf.sqrt(tf.cast(H, dtype=tf.float32))## we musst cast to float sqrt want just float32\n",
    "tf.math.log(tf.cast(H,dtype=tf.float32))# write datatype for log ist float32... nit int 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907efbf",
   "metadata": {},
   "source": [
    "### Tensors and Numpy:\n",
    "* Tensors interacts beautifully with Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b26e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbcdbfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "j=tf.constant(np.array([3.,7.,10.]))\n",
    "j\n",
    "# convert our tensorflow to array\n",
    "np.array(j)\n",
    "type(np.array(j))\n",
    "\n",
    "# other way to convert tensor to numpy:\n",
    "j.numpy()\n",
    "type(j.numpy())\n",
    "\n",
    "k=tf.constant([3.])\n",
    "k.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14aef915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out the type of tensor\n",
    "numpy_tensor= tf.constant(np.array([2.,3.,5.]))\n",
    "tensor_k=tf.constant([9.,8.,7.])\n",
    "numpy_tensor.dtype,tensor_k.dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651debb",
   "metadata": {},
   "source": [
    "## Neural Network Regression with TensorFlow\n",
    "*  Architecture of neural network regression model\n",
    "* Input shapes and output shapes of a regression model(features and labels)\n",
    "*  creating custom data view and fit\n",
    "* steps im modelling\n",
    "* creating a model, compilling a model , fitting a model, evaluationg a model\n",
    "* different evaluation methods\n",
    "* saving and loading models\n",
    "* important hyperparameter in nezral network\n",
    "            * input layer shape: same shape as number of features(eg.3  forbederom, bathrooms, car)\n",
    "            * hidden layer : problem specific, minimum m=1 maximum =unlimited\n",
    "            * Neurons per hidden layer: problem specific general 10 to 100\n",
    "            * output layer shape: same shape as desired prediction shape (e.g 1 for house price)\n",
    "            * hidden activation Usally RELU( rectified linear unit)\n",
    "            * output activation : None , Relu logistic/tanh\n",
    "            * Loss function :MSE (mean squareerror) or MAE(mean absolute error)\n",
    "            optimizer: SDG (stochastic gradient descent)\n",
    "#### create a model ( specified to your problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07018057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(100,activation=\"relu\"),#first layer has 100 nodes\n",
    "    tf.keras.layers.Dense(100,activation=\"relu\"),#second layer has 100 nodes\n",
    "    tf.keras.layers.Dense(100,activation=\"relu\"),#second layer has 100 nodes\n",
    "    tf.keras.layers.Dense(1,activation=None)])#1 shape pf predicted number it musst be just one number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d46dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00fff8ff",
   "metadata": {},
   "source": [
    "#### compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7568ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e299215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fit the model:\n",
    "#model.fit(X_train,Y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f7058",
   "metadata": {},
   "source": [
    "# Linear regreesion with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5434ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900d7d1",
   "metadata": {},
   "source": [
    "##### creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abfec245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79504224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the features:\n",
    "X=np.array([-7.0,-4.0,-1.0,2.0, 5.0,8.0,11.0,14.0])\n",
    "#create lables:\n",
    "Y=np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485cc01",
   "metadata": {},
   "source": [
    "###### visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08915210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x224d8a7d8b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bd1c256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y==X+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d40d1970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=int32, numpy=array([90300])>,\n",
       " <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### input and output shapes:\n",
    "house_info=tf.constant([\"bedroom\",\"bathroom\",\"garage\"])\n",
    "house_price=tf.constant([90300])\n",
    "house_price,house_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcaf10cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=X.shape\n",
    "output_shape=Y.shape\n",
    "input_shape,output_shape\n",
    "\n",
    "\n",
    "input_shape0=X[0].shape\n",
    "output_shape0=Y[0].shape\n",
    "input_shape0,output_shape0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b4f3d07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9a45778a888b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minput_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "#turn out input and output to tensor:\n",
    "X=tf.constant(X,dtype=tf.float32)\n",
    "Y=tf.constant(Y,dtype=tf.float32)\n",
    "\n",
    "input_tensor\n",
    "output_tensor\n",
    "\n",
    "input_tensor.shape\n",
    "output_tensor.shape\n",
    "\n",
    "input_shape1=input_tensor[0].shape\n",
    "output_shape1=output_tensor[0].shape\n",
    "input_shape1,output_shape1# when we have no dimension , its scaler dimension\n",
    "print(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f6f70",
   "metadata": {},
   "source": [
    "#### steps in modeling with tensorflow:\n",
    "* creating a model: define the input and output layers, as well as the hidden as the hidden layers of a deep learning model.\n",
    "* compiling the model : define the loss function ( in others words , the fucntion which tells our model how wrong it is) \n",
    "* the optimizer tellas our model how to improve  the patterns its learning \n",
    "* evaluation metrics  : what we cam use to interpret the performance of our model.\n",
    "* Fitting a model : letting the model try to find patterns between X & Y (features and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f8efc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 993us/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224d92b32b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed:\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. create a model using the sequential API:\n",
    "# actually there are   a lotof way to  create a sequential :\n",
    "#model=tf.keras.sequential(\n",
    "#model.add(tf.keras.layers.Dense(100)))\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model:\n",
    "# mae _ mean square error : 1/n sum(ytrue-ypred)\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model:\n",
    "model.fit(X,Y,epochs=5)# look at the data 5 time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4e60103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out X and Y\n",
    "\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4859bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe77023",
   "metadata": {},
   "source": [
    "## improve our model:\n",
    "* we can improve the model , by altering the steps we took to create a model:\n",
    "    **creating a model** :we might add more layers, increase the number of hidden units(all called neurons) within each of the hideen layers, change the activation function of each layer.\n",
    "    **compiling a model** we might change the optimization function or perhaps the **learning rate** of the optimization \n",
    "    **Fitting a model** we might fit a model for more epochs(leave it training for longer)or on more data (give the model more exmaples to lean from)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe5a5c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.2532 - mae: 19.2532\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.9720 - mae: 18.9720\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 496us/step - loss: 18.6907 - mae: 18.6907\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.4095 - mae: 18.4095\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.1282 - mae: 18.1282\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 17.8470 - mae: 17.8470\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 540us/step - loss: 17.5657 - mae: 17.5657\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 917us/step - loss: 17.2845 - mae: 17.2845\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 17.0032 - mae: 17.0032\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 16.7220 - mae: 16.7220\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 16.4407 - mae: 16.4407\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 16.1595 - mae: 16.1595\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.8782 - mae: 15.8782\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 15.5970 - mae: 15.5970\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 15.3157 - mae: 15.3157\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0345 - mae: 15.0345\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.7755 - mae: 14.7755\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 683us/step - loss: 14.6430 - mae: 14.6430\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 14.5105 - mae: 14.5105\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.3780 - mae: 14.3780\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.2455 - mae: 14.2455\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 14.1130 - mae: 14.1130\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 13.9805 - mae: 13.9805\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 665us/step - loss: 13.8480 - mae: 13.8480\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.7155 - mae: 13.7155\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 13.5830 - mae: 13.5830\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.4505 - mae: 13.4505\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 750us/step - loss: 13.3180 - mae: 13.3180\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1855 - mae: 13.1855\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.0530 - mae: 13.0530\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 12.9205 - mae: 12.9205\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 12.7880 - mae: 12.7880\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.6555 - mae: 12.6555\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 988us/step - loss: 12.5230 - mae: 12.5230\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 12.3905 - mae: 12.3905\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 12.2580 - mae: 12.2580\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 12.1255 - mae: 12.1255\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.9930 - mae: 11.9930\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.8605 - mae: 11.8605\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 531us/step - loss: 11.7280 - mae: 11.7280\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 940us/step - loss: 11.5955 - mae: 11.5955\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 11.4630 - mae: 11.4630\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 902us/step - loss: 11.3305 - mae: 11.3305\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1980 - mae: 11.1980\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 639us/step - loss: 11.0655 - mae: 11.0655\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 448us/step - loss: 10.9330 - mae: 10.9330\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8005 - mae: 10.8005\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 503us/step - loss: 10.6680 - mae: 10.6680\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5355 - mae: 10.5355\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.4030 - mae: 10.4030\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2705 - mae: 10.2705\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 582us/step - loss: 10.1380 - mae: 10.1380\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0055 - mae: 10.0055\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8730 - mae: 9.8730\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 9.7405 - mae: 9.7405\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6080 - mae: 9.6080\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4755 - mae: 9.4755\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 537us/step - loss: 9.3430 - mae: 9.3430\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2105 - mae: 9.2105\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 761us/step - loss: 9.0780 - mae: 9.0780\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9455 - mae: 8.9455\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.8130 - mae: 8.8130\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 658us/step - loss: 8.6805 - mae: 8.6805\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5480 - mae: 8.5480\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 672us/step - loss: 8.4155 - mae: 8.4155\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 8.2830 - mae: 8.2830\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 8.1505 - mae: 8.1505\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 531us/step - loss: 8.0180 - mae: 8.0180\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 805us/step - loss: 7.8855 - mae: 7.8855\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 710us/step - loss: 7.7530 - mae: 7.7530\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.6205 - mae: 7.6205\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 722us/step - loss: 7.4880 - mae: 7.4880\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 7.3555 - mae: 7.3555\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.2230 - mae: 7.2230\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 7.0905 - mae: 7.0905\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 506us/step - loss: 6.9675 - mae: 6.9675\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 722us/step - loss: 6.9619 - mae: 6.9619\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 496us/step - loss: 6.9563 - mae: 6.9563\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 872us/step - loss: 6.9506 - mae: 6.9506\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 700us/step - loss: 6.9450 - mae: 6.9450\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 591us/step - loss: 6.9394 - mae: 6.9394\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9338 - mae: 6.9338\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 597us/step - loss: 6.9281 - mae: 6.9281\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 674us/step - loss: 6.9225 - mae: 6.9225\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 787us/step - loss: 6.9169 - mae: 6.9169\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 581us/step - loss: 6.9113 - mae: 6.9113\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 496us/step - loss: 6.9056 - mae: 6.9056\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9000 - mae: 6.9000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8944 - mae: 6.8944\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 496us/step - loss: 6.8888 - mae: 6.8888\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 838us/step - loss: 6.8831 - mae: 6.8831\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 714us/step - loss: 6.8775 - mae: 6.8775\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8719 - mae: 6.8719\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 496us/step - loss: 6.8663 - mae: 6.8663\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 495us/step - loss: 6.8606 - mae: 6.8606\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 630us/step - loss: 6.8550 - mae: 6.8550\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8494 - mae: 6.8494\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 694us/step - loss: 6.8438 - mae: 6.8438\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 505us/step - loss: 6.8381 - mae: 6.8381\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8325 - mae: 6.8325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224dc360400>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's rebuild the model:\n",
    "# 1. create the model:\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "#compile the model:\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]            \n",
    "             )\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc80f0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.39101]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let 's if  the prediction has impoved:\n",
    "y_neupredited=model.predict([17.10])\n",
    "y_neupredited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd1aad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1407 - mae: 13.1407\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4751 - mae: 12.4751\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.8029 - mae: 11.8029\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1216 - mae: 11.1216\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4260 - mae: 10.4260\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.7259 - mae: 9.7259\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9961 - mae: 8.9961\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2333 - mae: 8.2333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 7.4276 - mae: 7.4276\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 619us/step - loss: 6.5690 - mae: 6.5690\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 573us/step - loss: 5.6583 - mae: 5.6583\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6803 - mae: 4.6803\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 496us/step - loss: 4.1211 - mae: 4.1211\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0120 - mae: 4.0120\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0106 - mae: 4.0106\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 571us/step - loss: 3.9347 - mae: 3.9347\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9456 - mae: 3.9456\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 3.9462 - mae: 3.9462\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 660us/step - loss: 3.9203 - mae: 3.9203\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 3.9537 - mae: 3.9537\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8948 - mae: 3.8948\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 709us/step - loss: 3.9614 - mae: 3.9614\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 506us/step - loss: 3.8919 - mae: 3.8919\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9462 - mae: 3.9462\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 3.9064 - mae: 3.9064\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9264 - mae: 3.9264\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 585us/step - loss: 3.9140 - mae: 3.9140\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 717us/step - loss: 3.9008 - mae: 3.9008\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.9217 - mae: 3.9217\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 741us/step - loss: 3.8752 - mae: 3.8752\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 3.9295 - mae: 3.9295\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 623us/step - loss: 3.8604 - mae: 3.8604\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9299 - mae: 3.9299\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 3.8752 - mae: 3.8752\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 3.9059 - mae: 3.9059\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.8831 - mae: 3.8831\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 746us/step - loss: 3.8800 - mae: 3.8800\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8911 - mae: 3.8911\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8541 - mae: 3.8541\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8991 - mae: 3.8991\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 543us/step - loss: 3.8315 - mae: 3.8315\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 703us/step - loss: 3.9101 - mae: 3.9101\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8453 - mae: 3.8453\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8841 - mae: 3.8841\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 3.8534 - mae: 3.8534\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8581 - mae: 3.8581\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8616 - mae: 3.8616\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8320 - mae: 3.8320\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 3.8698 - mae: 3.8698\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 591us/step - loss: 3.8099 - mae: 3.8099\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 597us/step - loss: 3.8850 - mae: 3.8850\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8164 - mae: 3.8164\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8613 - mae: 3.8613\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8247 - mae: 3.8247\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8348 - mae: 3.8348\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 591us/step - loss: 3.8331 - mae: 3.8331\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8084 - mae: 3.8084\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 674us/step - loss: 3.8420 - mae: 3.8420\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 509us/step - loss: 3.7881 - mae: 3.7881\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 620us/step - loss: 3.8569 - mae: 3.8569\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 683us/step - loss: 3.7887 - mae: 3.7887\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 3.8371 - mae: 3.8371\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 3.7972 - mae: 3.7972\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 3.8103 - mae: 3.8103\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 500us/step - loss: 3.8058 - mae: 3.8058\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7836 - mae: 3.7836\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 718us/step - loss: 3.8177 - mae: 3.8177\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 706us/step - loss: 3.7629 - mae: 3.7629\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 894us/step - loss: 3.8300 - mae: 3.8300\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 805us/step - loss: 3.7620 - mae: 3.7620\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8115 - mae: 3.8115\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 3.7707 - mae: 3.7707\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 608us/step - loss: 3.7845 - mae: 3.7845\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 503us/step - loss: 3.7796 - mae: 3.7796\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7574 - mae: 3.7574\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7944 - mae: 3.7944\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7364 - mae: 3.7364\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8042 - mae: 3.8042\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 513us/step - loss: 3.7365 - mae: 3.7365\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7846 - mae: 3.7846\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7454 - mae: 3.7454\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 510us/step - loss: 3.7573 - mae: 3.7573\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 654us/step - loss: 3.7544 - mae: 3.7544\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7322 - mae: 3.7322\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7704 - mae: 3.7704\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7085 - mae: 3.7085\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 508us/step - loss: 3.7794 - mae: 3.7794\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 993us/step - loss: 3.7120 - mae: 3.7120\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 3.7563 - mae: 3.7563\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7211 - mae: 3.7211\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 501us/step - loss: 3.7287 - mae: 3.7287\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7304 - mae: 3.7304\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 3.7058 - mae: 3.7058\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 641us/step - loss: 3.7464 - mae: 3.7464\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 3.6795 - mae: 3.6795\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 3.7544 - mae: 3.7544\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6886 - mae: 3.6886\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 3.7266 - mae: 3.7266\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 669us/step - loss: 3.6979 - mae: 3.6979\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 679us/step - loss: 3.6986 - mae: 3.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224dc5d68b0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see if we can make another change to improve our prediction:\n",
    "# this time we gonna create one more hidden layer with extra 100 neurons\n",
    "#1. creare the model :\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation ='relu' ),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# compile the model:\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "# fit the model\n",
    "model.fit(X,Y,epochs=100)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55d99635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34f00e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32.624386]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted=model.predict([17.0])\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e18755",
   "metadata": {},
   "source": [
    "#### commom ways to improve a deep model:\n",
    "**Adding layers**-- \n",
    "**Increase the  Number of hidden units**--\n",
    "**Change the activation functions**--\n",
    "**change the optimization function**--\n",
    "**change the learning rate**--\n",
    "**fitting for longer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc1ddd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.3469 - mae: 12.3469\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.6170 - mae: 11.6170\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1465 - mae: 10.1465\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 9.4040 - mae: 9.4040\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6532 - mae: 8.6532\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 7.8904 - mae: 7.8904\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 870us/step - loss: 7.1120 - mae: 7.1120\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8174 - mae: 6.8174\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 846us/step - loss: 7.1412 - mae: 7.1412\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 497us/step - loss: 7.4160 - mae: 7.4160\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.7229 - mae: 7.7229\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.7818 - mae: 7.7818\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.6395 - mae: 7.6395\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3493 - mae: 7.3493\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 7.0024 - mae: 7.0024\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7269 - mae: 6.7269\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 605us/step - loss: 6.4364 - mae: 6.4364\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1431 - mae: 6.1431\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 507us/step - loss: 6.0919 - mae: 6.0919\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0366 - mae: 6.0366\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 865us/step - loss: 6.1774 - mae: 6.1774\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 6.2159 - mae: 6.2159\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 6.1539 - mae: 6.1539\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0036 - mae: 6.0036\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 5.7739 - mae: 5.7739\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5313 - mae: 5.5313\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 5.4211 - mae: 5.4211\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3081 - mae: 5.3081\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 5.2965 - mae: 5.2965\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 5.2780 - mae: 5.2780\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 506us/step - loss: 5.2141 - mae: 5.2141\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1082 - mae: 5.1082\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 4.9639 - mae: 4.9639\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 787us/step - loss: 4.7844 - mae: 4.7844\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.5777 - mae: 4.5777\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 655us/step - loss: 4.4758 - mae: 4.4758\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 4.3666 - mae: 4.3666\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 4.2498 - mae: 4.2498\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1323 - mae: 4.1323\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9836 - mae: 3.9836\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 876us/step - loss: 3.8347 - mae: 3.8347\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 726us/step - loss: 3.6784 - mae: 3.6784\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 509us/step - loss: 3.5146 - mae: 3.5146\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 3.3429 - mae: 3.3429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 984us/step - loss: 3.1692 - mae: 3.1692\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9985 - mae: 2.9985\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 2.8128 - mae: 2.8128\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 639us/step - loss: 2.6285 - mae: 2.6285\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 2.4338 - mae: 2.4338\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2285 - mae: 2.2285\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0123 - mae: 2.0123\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 1.7852 - mae: 1.7852\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 615us/step - loss: 1.5469 - mae: 1.5469\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 514us/step - loss: 1.2972 - mae: 1.2972\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0368 - mae: 1.0368\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.7763 - mae: 0.7763\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5451 - mae: 0.5451\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2720 - mae: 0.2720\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0768 - mae: 0.0768\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 610us/step - loss: 0.3693 - mae: 0.3693\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.4941 - mae: 0.4941\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 576us/step - loss: 0.5882 - mae: 0.5882\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 478us/step - loss: 0.7020 - mae: 0.7020\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.6968 - mae: 0.6968\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.7073 - mae: 0.7073\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.6074 - mae: 0.6074\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5281 - mae: 0.5281\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 645us/step - loss: 0.4097 - mae: 0.4097\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2869 - mae: 0.2869\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2769 - mae: 0.2769\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 635us/step - loss: 0.0608 - mae: 0.0608\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4015 - mae: 0.4015\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4353 - mae: 0.4353\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2603 - mae: 0.2603\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.3222 - mae: 0.3222\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2612 - mae: 0.2612\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.2212 - mae: 0.2212\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1594 - mae: 0.1594\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0904 - mae: 0.0904\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1716 - mae: 0.1716\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 729us/step - loss: 0.1388 - mae: 0.1388\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.2165 - mae: 0.2165\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1966 - mae: 0.1966\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1677 - mae: 0.1677\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.1395 - mae: 0.1395\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0454 - mae: 0.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1130 - mae: 0.1130\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1426 - mae: 0.1426\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.1916 - mae: 0.1916\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1534 - mae: 0.1534\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1144 - mae: 0.1144\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0577 - mae: 0.0577\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1123 - mae: 0.1123\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.1674 - mae: 0.1674\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.1911 - mae: 0.1911\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.1582 - mae: 0.1582\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1128 - mae: 0.1128\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.1844 - mae: 0.1844\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0933 - mae: 0.0933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224dc880cd0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model:\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50,activation=None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# compile the model:\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics=[\"mae\"]\n",
    "             )\n",
    "#fit the model:\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "656c3f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.209171]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predited=model.predict([17.0])\n",
    "y_predited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff66fb",
   "metadata": {},
   "source": [
    "#### Evaluating the model:\n",
    "* in practice , a typical workflow you will go through when building neural network is:\n",
    "**build a model-->fit it-->ecaluate it-->tweak a model-->fit it-->evaluate it--> tweak a model-->fit it-->evaluate it**\n",
    "\n",
    "##### when it comes to evaluation ... there are 3 words you should memorize:\n",
    "**Visualize,Visualize,Visualize**\n",
    "* it's a good idea to visualize:\n",
    "* the data- what data are we working with? what does it look like?\n",
    "* the model itself-what does our model look like?\n",
    "* the training of a model - how does a model perform while it learns?\n",
    "* the predictions of the model- how do the predictions of a model line up against the ground truth (the original labels)? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5cf2b26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### make a bigger dataset:\n",
    "X=tf.range(-100,100,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70a34bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make labels for the dataset:\n",
    "Y=X+10\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a5890bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x224ddb0fd00>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the data:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218ec6f",
   "metadata": {},
   "source": [
    "### bevor we getting to visualizing , let's take concept of the 3 sets\n",
    "* **training set**_ the model learn from this data typically 70-80%\n",
    "* **validation set**: the model get tuned on this data typically 10-15%\n",
    "* **the test set** : the model gets evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3c4be46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the leng of the dataset:\n",
    "len(X)\n",
    "# split the data into training and test dataset:\n",
    "x_train=X[:40]# 80% of the data\n",
    "y_train=Y[:40]\n",
    "x_test=X[:10]# the last 10% of the data\n",
    "y_test=Y[:10]\n",
    "\n",
    "len(x_train),len(x_test),len(y_train),len(y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "21a1b261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x224df926730>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visualizing the data: \n",
    "plt.figure(figsize=(10,7))\n",
    "# plot the trainig data in blue\n",
    "plt.scatter(x_train,y_train, c=\"b\",label=\"Training_data\")\n",
    "#plot the testdata\n",
    "plt.scatter(x_test,y_test,c=\"red\",label=\"test_data \")\n",
    "#show legend\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9a8ea82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6049 - mae: 8.6049\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 597us/step - loss: 10.4695 - mae: 10.4695\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 780us/step - loss: 10.9015 - mae: 10.9015\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4167 - mae: 9.4167\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 802us/step - loss: 10.3042 - mae: 10.3042\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5497 - mae: 9.5497\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6695 - mae: 8.6695\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 870us/step - loss: 9.0480 - mae: 9.0480\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 743us/step - loss: 19.0087 - mae: 19.0087\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.2539 - mae: 10.2539\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 765us/step - loss: 8.4495 - mae: 8.4495\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 547us/step - loss: 10.7747 - mae: 10.7747\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8437 - mae: 9.8437\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9966 - mae: 11.9966\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 655us/step - loss: 12.4943 - mae: 12.4943\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 7.9004 - mae: 7.9004\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 12.8050 - mae: 12.8050\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4282 - mae: 10.4282\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 992us/step - loss: 19.2804 - mae: 19.2804\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 790us/step - loss: 15.9429 - mae: 15.9429\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8639 - mae: 11.8639\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4705 - mae: 8.4705\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 670us/step - loss: 9.7952 - mae: 9.7952\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 777us/step - loss: 10.8314 - mae: 10.8314\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1031 - mae: 9.1031\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 766us/step - loss: 13.0605 - mae: 13.0605\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 10.3931 - mae: 10.3931\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3990 - mae: 13.3990\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6034 - mae: 9.6034\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 605us/step - loss: 17.2207 - mae: 17.2207\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 766us/step - loss: 22.8368 - mae: 22.8368\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 771us/step - loss: 7.9057 - mae: 7.9057\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 604us/step - loss: 14.1503 - mae: 14.1503\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 785us/step - loss: 12.3998 - mae: 12.3998\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 960us/step - loss: 8.2432 - mae: 8.2432\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.4565 - mae: 10.4565\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 829us/step - loss: 10.1052 - mae: 10.1052\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 11.2882 - mae: 11.2882\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 769us/step - loss: 14.7719 - mae: 14.7719\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 784us/step - loss: 12.9020 - mae: 12.9020\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 9.2944 - mae: 9.2944\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.9741 - mae: 10.9741\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 8.3201 - mae: 8.3201\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 896us/step - loss: 13.0091 - mae: 13.0091\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6962 - mae: 13.6962\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3955 - mae: 8.3955\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 743us/step - loss: 9.1666 - mae: 9.1666\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 10.6734 - mae: 10.6734\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7788 - mae: 7.7788\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 9.5900 - mae: 9.5900\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1619 - mae: 9.1619\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 16.4882 - mae: 16.4882\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 893us/step - loss: 14.0664 - mae: 14.0664\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 806us/step - loss: 20.9770 - mae: 20.9770\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5072 - mae: 16.5072\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 575us/step - loss: 9.8425 - mae: 9.8425\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 820us/step - loss: 9.6572 - mae: 9.6572\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 582us/step - loss: 8.9740 - mae: 8.9740\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 755us/step - loss: 10.1882 - mae: 10.1882\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 591us/step - loss: 8.4012 - mae: 8.4012\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2350 - mae: 9.2350\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 779us/step - loss: 7.2649 - mae: 7.2649\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.1708 - mae: 8.1708\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 812us/step - loss: 12.5349 - mae: 12.5349\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 938us/step - loss: 10.6128 - mae: 10.6128\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 15.4632 - mae: 15.4632\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 612us/step - loss: 9.9029 - mae: 9.9029\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 667us/step - loss: 8.6719 - mae: 8.6719\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 763us/step - loss: 13.3368 - mae: 13.3368\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 763us/step - loss: 7.4624 - mae: 7.4624\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 696us/step - loss: 12.3397 - mae: 12.3397\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 520us/step - loss: 8.4475 - mae: 8.4475\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 6.8676 - mae: 6.8676\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 789us/step - loss: 11.0517 - mae: 11.0517\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 9.4064 - mae: 9.4064\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 763us/step - loss: 10.8619 - mae: 10.8619\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 817us/step - loss: 14.8049 - mae: 14.8049\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.8764 - mae: 10.8764\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.3280 - mae: 15.3280\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 633us/step - loss: 11.7601 - mae: 11.7601\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 739us/step - loss: 9.2041 - mae: 9.2041\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 607us/step - loss: 12.8529 - mae: 12.8529\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 679us/step - loss: 10.3077 - mae: 10.3077\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 588us/step - loss: 10.5865 - mae: 10.5865\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 776us/step - loss: 9.3008 - mae: 9.3008\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 552us/step - loss: 9.1542 - mae: 9.1542\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.8775 - mae: 11.8775\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 771us/step - loss: 10.4872 - mae: 10.4872\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 6.9689 - mae: 6.9689\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 564us/step - loss: 13.8167 - mae: 13.8167\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 595us/step - loss: 7.8833 - mae: 7.8833\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 802us/step - loss: 7.4496 - mae: 7.4496\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1536 - mae: 9.1536\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 8.5577 - mae: 8.5577\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 588us/step - loss: 11.4997 - mae: 11.4997\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 542us/step - loss: 10.2886 - mae: 10.2886\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6817 - mae: 7.6817\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 974us/step - loss: 8.6165 - mae: 8.6165\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 807us/step - loss: 9.3955 - mae: 9.3955\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 765us/step - loss: 8.8401 - mae: 8.8401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224de6f4a00>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model:\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "#compile the model:\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "#fitting the model:\n",
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9810c039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "74d3e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let'create a model which builds automatically by defining the input_shape argument\n",
    "tf.random.set_seed(42)\n",
    "#create the model (same as above)\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1,input_shape=[1],name=\"input_layer\"),#  input_shape=[1],we have just one feature, und we predite just one value\n",
    "    #tf.keras.layers.Dense(1,name=\"output_layer\") \n",
    "],name=\"model_1\")\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "#dense_29 (Dense)            \n",
    "#(None, 4)  we have 4 neuron in a layer               \n",
    "#12  the total combination  between output und neurons\n",
    "# total params beziehung zwischen input-layer und outpout  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699b110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d4cdc1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969ba81",
   "metadata": {},
   "source": [
    "* **total params**- total number of parameters in the model= 2, 1 input one output.\n",
    "* **trainable parameters**- tehse are teh parameters(patterns) the model can update as it trains\n",
    "* **Non-trainable params**- these parameters are not updated during the training(this is typical when you bring in already learn patterns or parametrs from other models during **transferlearning***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1baa75ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224dfcef310>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's fit our model to the training data:\n",
    "model.fit(x_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b010ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d5caee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#get a summary of our model:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ad4b3858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model=model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "936c6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulazing our model's predictions:\n",
    "#to visualize predictions, it's a good  idea to plot them against the ground truth labels\n",
    "# often you will see this in the form of y_test or y_true versus y_pred( ground truth versus yours model prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0f36bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224DF740940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-85.838486],\n",
       "       [-82.35325 ],\n",
       "       [-78.868004],\n",
       "       [-75.38277 ],\n",
       "       [-71.89753 ],\n",
       "       [-68.412285],\n",
       "       [-64.92705 ],\n",
       "       [-61.44181 ],\n",
       "       [-57.956573],\n",
       "       [-54.471333]], dtype=float32)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b9009",
   "metadata": {},
   "source": [
    "#### if we are going to use some kinf of funktionality in the  future, it will be better to put it , in form of fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e22621de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(train_data=x_train,train_label=y_train,\n",
    "                    test_data=x_test, test_label=y_test, predictions=y_pred):\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(train_data,train_label,c='b',label='training_data')\n",
    "    plt.scatter(test_data,test_label,c='g',label='testing_data')\n",
    "    plt.scatter(x_test,predictions,c='r',label='predictions')\n",
    "    plt.legend();\n",
    "    \n",
    "\n",
    "plot_predictions()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c378fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluating our model's predictions with regression evaluation metrics:\n",
    "#### Depending on the problem you are working on , tehre will be different evaluation metrics\n",
    "####  to evaluate the model , since we are working on a regression , two of the main , metrics:\n",
    "#### **MAE** mean absoulte error  on average , how wrong is each of my model's predictions\n",
    "#### **MSE** mean square error, square the average errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d726f128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9394 - mae: 1.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.939358115196228, 1.939358115196228]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7e6fa4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([14.703092, 12.611949, 11.147202, 10.276553, 10.      , 10.317543,\n",
       "       11.229181, 12.734914, 14.834742, 17.622936], dtype=float32)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absulte error:\n",
    "# we get a list of value , however in the model evalute we get just a number ...?\n",
    "tf.metrics.mean_absolute_error(y_test, tf.constant(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "65af99b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-85.838486],\n",
       "       [-82.35325 ],\n",
       "       [-78.868004],\n",
       "       [-75.38277 ],\n",
       "       [-71.89753 ],\n",
       "       [-68.412285],\n",
       "       [-64.92705 ],\n",
       "       [-61.44181 ],\n",
       "       [-57.956573],\n",
       "       [-54.471333]], dtype=float32)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "63aa5522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54])>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we should put y_pred and y_test in the same shape--- squueze\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8b4be5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-85.838486, -82.35325 , -78.868004, -75.38277 , -71.89753 ,\n",
       "       -68.412285, -64.92705 , -61.44181 , -57.956573, -54.471333],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "18b64555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.9393581>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculte the mean absulte error:\n",
    "mae= tf.metrics.mean_absolute_error(y_test,tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b6f67660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.5904374>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the  mean square error:\n",
    "mse=tf.keras.losses.MSE(y_test,tf.squeeze(y_pred))\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "190e08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some  fuction to reuse MSE and MAE:\n",
    "def mae(y_true,y_pred):\n",
    "    return (tf.metrics.mean_absolute_error(y_true=y_true,y_pred=tf.squeeze(y_pred))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "53fdfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return (tf.keras.losses.MSE(y_true=y_true,y_pred=tf.squeeze(y_pred))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a714853",
   "metadata": {},
   "source": [
    "##### how to minimize the diference between the y_true and y_pred:\n",
    "* running experiment to improve our model\n",
    "* Build a model--> fit it--> evaluate it--> twak it--> fit it--> evaluate it--> twak it --> fit it -- > evaluate it...\n",
    "    * 1. get more data - get more examples for your model to train on( more apportunity to lean patterns or relationship between features and labels)\n",
    "    * 2. make your model larger (using a more complex model)- this might come in the form of using more hidden layers or more neuron in hidden layers\n",
    "    * 3.  train for longer - give your model more of a chance to find patterns in the data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b6acb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb3389",
   "metadata": {},
   "source": [
    "###### let'S do 3 modelling experiments:\n",
    "* model 1: same as the original model , 1 layer , trained for 100 epochs\n",
    "* model 2 : 2 layers, trained for 100 epochs\n",
    "* model 3: 2 layers , trained for 500 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe272a",
   "metadata": {},
   "source": [
    "** Build model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b9941f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 883us/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 653us/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 580us/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 538us/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 831us/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 842us/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 623us/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 550us/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 762us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 582us/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 618us/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 749us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 803us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 630us/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 802us/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 850us/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 782us/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 588us/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 769us/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 601us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 506us/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 803us/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 780us/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 721us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 781us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 603us/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 811us/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 548us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 823us/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 874us/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 878us/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 851us/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 606us/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 911us/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 755us/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 763us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 777us/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 579us/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 948us/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 947us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 655us/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 584us/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 814us/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 915us/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 762us/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 599us/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 790us/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 976us/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 704us/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 907us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 896us/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 754us/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 834us/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 792us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 850us/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 805us/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 558us/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 932us/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 777us/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 613us/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 525us/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 628us/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 546us/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 585us/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224e5f1b700>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random set\n",
    "tf.random.set_seed(42)\n",
    "# crete the model\n",
    "model_1=tf.keras.Sequential([\n",
    "   tf.keras.layers.Dense(1)\n",
    "])\n",
    "# compile the model:\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['mae'],\n",
    "             )\n",
    "#fit the model\n",
    "model_1.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "04d2a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224E612A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### make and plot predictions for model_1:\n",
    "y_pred_1=model_1.predict(x_test)\n",
    "plot_predictions(predictions=y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "dd7c0867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 1)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "#y_test and y_pred should  habe the same diemstion\n",
    "print(y_test.shape)\n",
    "print(y_pred_1.shape)\n",
    "# you see here there don't have the same shap that'S mean our mea ,mse\n",
    "# gonna be a matrix not arela value, so we should squeeze  the value of y_pred_1\n",
    "# to minimize it'S size\n",
    "print(tf.squeeze(y_pred_1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b7f8b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9393581\n",
      "5.5904374\n"
     ]
    }
   ],
   "source": [
    "# evaluation matrix for model_1\n",
    "mae_1=mae(y_test,y_pred_1)\n",
    "mse_1=mse(y_test,y_pred_1)\n",
    "print(mae_1)\n",
    "print(mse_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ffb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build model 2 with 2 hidden layers trained for 100 epochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "258b6b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 886us/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 754us/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 790us/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 593us/step - loss: 27.8687 - mae: 27.8687\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 860us/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 837us/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 567us/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 824us/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 762us/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 590us/step - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 578us/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 599us/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 556us/step - loss: 53.0224 - mae: 53.0224\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 806us/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 810us/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 845us/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 614us/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 884us/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 768us/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 615us/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 866us/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 779us/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 640us/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 765us/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 759us/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 897us/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 810us/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 821us/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 527us/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 576us/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 812us/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 750us/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 876us/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 750us/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 768us/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 651us/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 639us/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 746us/step - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 828us/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 821us/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 771us/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 755us/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 828us/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 776us/step - loss: 9.5896 - mae: 9.5896\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 862us/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 539us/step - loss: 16.6488 - mae: 16.6488\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 804us/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 656us/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.7463 - mae: 26.7463\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 798us/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 583us/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 986us/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 669us/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 836us/step - loss: 29.8228 - mae: 29.8228\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 742us/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 752us/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 761us/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 566us/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 781us/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 611us/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 745us/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 751us/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 588us/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 695us/step - loss: 20.2277 - mae: 20.2277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224e5b00a30>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# create the model:\n",
    "model_2=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "#compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# fit the model_2\n",
    "model_2.fit(x_train,y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b2e56c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224E599D9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_2=model_2.predict(x_test)\n",
    "plot_predictions(predictions=y_pred_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "3bfb5c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.312002\n",
      "415.42715\n"
     ]
    }
   ],
   "source": [
    "mae_2=mae(y_test,y_pred_2)\n",
    "mse_2=mse(y_test,y_pred_2)\n",
    "print(mae_2)\n",
    "print(mse_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "97b10ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36.0963 - mae: 36.0963\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.7401 - mae: 28.7401\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.2070 - mae: 33.2070\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.5341 - mae: 30.5341\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5504 - mae: 15.5504\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.3355 - mae: 12.3355\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6147 - mae: 11.6147\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 870us/step - loss: 11.2547 - mae: 11.2547\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 42.3778 - mae: 42.3778\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.5266 - mae: 29.5266\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 539us/step - loss: 7.7261 - mae: 7.7261\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 726us/step - loss: 28.5424 - mae: 28.5424\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.5152 - mae: 11.5152\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 795us/step - loss: 30.3047 - mae: 30.3047\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 575us/step - loss: 20.0565 - mae: 20.0565\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 552us/step - loss: 9.9328 - mae: 9.9328\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.8815 - mae: 17.8815\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 14.3561 - mae: 14.3561\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 14.4636 - mae: 14.4636\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 966us/step - loss: 10.4766 - mae: 10.4766\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 15.2397 - mae: 15.2397\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 819us/step - loss: 15.5822 - mae: 15.5822\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2367 - mae: 9.2367\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 17.2403 - mae: 17.2403\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 754us/step - loss: 15.9221 - mae: 15.9221\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8897 - mae: 20.8897\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 580us/step - loss: 26.0552 - mae: 26.0552\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 18.5411 - mae: 18.5411\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2471 - mae: 9.2471\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 29.1607 - mae: 29.1607\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 541us/step - loss: 52.8241 - mae: 52.8241\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 915us/step - loss: 11.9582 - mae: 11.9582\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5699 - mae: 15.5699\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 12.6486 - mae: 12.6486\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 551us/step - loss: 9.2216 - mae: 9.2216\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5660 - mae: 16.5660\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 785us/step - loss: 11.0633 - mae: 11.0633\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 18.1905 - mae: 18.1905\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.1255 - mae: 19.1255\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 20.4755 - mae: 20.4755\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 797us/step - loss: 14.8601 - mae: 14.8601\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2435 - mae: 12.2435\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7142 - mae: 10.7142\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 564us/step - loss: 22.9105 - mae: 22.9105\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3591 - mae: 10.3591\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 647us/step - loss: 11.7430 - mae: 11.7430\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 798us/step - loss: 9.6661 - mae: 9.6661\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 17.2796 - mae: 17.2796\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5457 - mae: 9.5457\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 767us/step - loss: 13.7675 - mae: 13.7675\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.5782 - mae: 11.5782\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 586us/step - loss: 30.4150 - mae: 30.4150\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 839us/step - loss: 14.2947 - mae: 14.2947\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.6385 - mae: 23.6385\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.5678 - mae: 24.5678\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.3286 - mae: 11.3286\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3457 - mae: 13.3457\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 939us/step - loss: 9.9385 - mae: 9.9385\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 860us/step - loss: 13.9017 - mae: 13.9017\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9821 - mae: 9.9821\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 709us/step - loss: 14.9607 - mae: 14.9607\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 834us/step - loss: 11.9163 - mae: 11.9163\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.2802 - mae: 10.2802\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 835us/step - loss: 23.8796 - mae: 23.8796\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 622us/step - loss: 10.4570 - mae: 10.4570\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 20.9281 - mae: 20.9281\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4360 - mae: 10.4360\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 851us/step - loss: 14.1740 - mae: 14.1740\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5085 - mae: 10.5085\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.5800 - mae: 12.5800\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0114 - mae: 13.0114\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.3658 - mae: 19.3658\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 872us/step - loss: 11.1257 - mae: 11.1257\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 765us/step - loss: 21.6094 - mae: 21.6094\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 843us/step - loss: 7.2224 - mae: 7.2224\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 9.4544 - mae: 9.4544\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.1672 - mae: 22.1672\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 614us/step - loss: 17.4700 - mae: 17.4700\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.7073 - mae: 14.7073\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 808us/step - loss: 24.8778 - mae: 24.8778\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 744us/step - loss: 10.7835 - mae: 10.7835\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.8246 - mae: 12.8246\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.6222 - mae: 17.6222\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 540us/step - loss: 7.2967 - mae: 7.2967\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 777us/step - loss: 15.1140 - mae: 15.1140\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 15.4042 - mae: 15.4042\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.3471 - mae: 19.3471\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 29.1969 - mae: 29.1969\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.0793 - mae: 10.0793\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.0153 - mae: 21.0153\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4465 - mae: 10.4465\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 940us/step - loss: 17.9444 - mae: 17.9444\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 6.5489 - mae: 6.5489\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 594us/step - loss: 11.1056 - mae: 11.1056\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.3362 - mae: 24.3362\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7118 - mae: 10.7118\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.3348 - mae: 15.3348\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2338 - mae: 8.2338\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5159 - mae: 16.5159\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 557us/step - loss: 14.2930 - mae: 14.2930\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 526us/step - loss: 15.2926 - mae: 15.2926\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7614 - mae: 10.7614\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1706 - mae: 9.1706\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 844us/step - loss: 23.8572 - mae: 23.8572\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8447 - mae: 10.8447\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 11.3009 - mae: 11.3009\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.4280 - mae: 21.4280\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 6.5884 - mae: 6.5884\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 774us/step - loss: 13.2925 - mae: 13.2925\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 684us/step - loss: 7.9929 - mae: 7.9929\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.7824 - mae: 15.7824\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7380 - mae: 8.7380\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 769us/step - loss: 22.6196 - mae: 22.6196\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 755us/step - loss: 18.9748 - mae: 18.9748\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 893us/step - loss: 11.0729 - mae: 11.0729\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 559us/step - loss: 23.0626 - mae: 23.0626\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 553us/step - loss: 9.5528 - mae: 9.5528\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6122 - mae: 10.6122\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 8.0394 - mae: 8.0394\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 566us/step - loss: 29.3525 - mae: 29.3525\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0766 - mae: 8.0766\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 929us/step - loss: 28.0279 - mae: 28.0279\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 620us/step - loss: 32.5532 - mae: 32.5532\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 775us/step - loss: 19.3723 - mae: 19.3723\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5279 - mae: 9.5279\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 936us/step - loss: 9.6005 - mae: 9.6005\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.7252 - mae: 12.7252\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 12.8221 - mae: 12.8221\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 868us/step - loss: 13.9553 - mae: 13.9553\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 10.2404 - mae: 10.2404\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.7224 - mae: 21.7224\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 764us/step - loss: 8.2835 - mae: 8.2835\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 9.0640 - mae: 9.0640\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.9153 - mae: 16.9153\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 820us/step - loss: 10.6593 - mae: 10.6593\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 18.5231 - mae: 18.5231\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.5168 - mae: 23.5168\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 749us/step - loss: 9.2856 - mae: 9.2856\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 9.0158 - mae: 9.0158\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 16.9776 - mae: 16.9776\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 8.3210 - mae: 8.3210\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 34.0542 - mae: 34.0542\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.1092 - mae: 23.1092\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 591us/step - loss: 11.3329 - mae: 11.3329\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.0300 - mae: 25.0300\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 962us/step - loss: 11.1595 - mae: 11.1595\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.0812 - mae: 14.0812\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 856us/step - loss: 16.9288 - mae: 16.9288\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 756us/step - loss: 9.2557 - mae: 9.2557\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9403 - mae: 7.9403\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 16.5058 - mae: 16.5058\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7998 - mae: 9.7998\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.8446 - mae: 26.8446\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 777us/step - loss: 11.9201 - mae: 11.9201\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 930us/step - loss: 15.2860 - mae: 15.2860\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6578 - mae: 16.6578\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 19.2727 - mae: 19.2727\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 614us/step - loss: 8.2579 - mae: 8.2579\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9875 - mae: 7.9875\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 20.9650 - mae: 20.9650\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 23.7713 - mae: 23.7713\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 776us/step - loss: 18.6937 - mae: 18.6937\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 771us/step - loss: 17.6474 - mae: 17.6474\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 806us/step - loss: 11.0684 - mae: 11.0684\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 9.6167 - mae: 9.6167\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.5682 - mae: 21.5682\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 26.3500 - mae: 26.3500\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.8827 - mae: 9.8827\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 579us/step - loss: 22.6144 - mae: 22.6144\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 622us/step - loss: 10.1510 - mae: 10.1510\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 678us/step - loss: 18.0297 - mae: 18.0297\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 28.8803 - mae: 28.8803\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 16.5673 - mae: 16.5673\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 11.2162 - mae: 11.2162\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.5747 - mae: 27.5747\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 8.2951 - mae: 8.2951\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 850us/step - loss: 9.2831 - mae: 9.2831\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 18.1694 - mae: 18.1694\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 10.5933 - mae: 10.5933\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 744us/step - loss: 7.9191 - mae: 7.9191\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 913us/step - loss: 17.4144 - mae: 17.4144\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 752us/step - loss: 11.0304 - mae: 11.0304\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 801us/step - loss: 11.7114 - mae: 11.7114\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 828us/step - loss: 30.4060 - mae: 30.4060\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 830us/step - loss: 7.5714 - mae: 7.5714\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 568us/step - loss: 16.0002 - mae: 16.0002\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.5732 - mae: 8.5732\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.7091 - mae: 28.7091\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 13.1805 - mae: 13.1805\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3237 - mae: 18.3237\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 13.7539 - mae: 13.7539\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 580us/step - loss: 13.7230 - mae: 13.7230\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 565us/step - loss: 28.5966 - mae: 28.5966\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 770us/step - loss: 7.0713 - mae: 7.0713\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 7.0699 - mae: 7.0699\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 768us/step - loss: 22.0338 - mae: 22.0338\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 815us/step - loss: 20.7913 - mae: 20.7913\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 751us/step - loss: 12.4453 - mae: 12.4453\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 744us/step - loss: 17.8630 - mae: 17.8630\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 548us/step - loss: 13.7067 - mae: 13.7067\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 592us/step - loss: 5.4883 - mae: 5.4883\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 635us/step - loss: 13.6583 - mae: 13.6583\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 594us/step - loss: 9.4133 - mae: 9.4133\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 754us/step - loss: 20.8961 - mae: 20.8961\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 505us/step - loss: 9.5333 - mae: 9.5333\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 11.6954 - mae: 11.6954\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 589us/step - loss: 14.3130 - mae: 14.3130\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 729us/step - loss: 14.8061 - mae: 14.8061\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 804us/step - loss: 14.5959 - mae: 14.5959\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 891us/step - loss: 17.8310 - mae: 17.8310\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 552us/step - loss: 9.8222 - mae: 9.8222\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 787us/step - loss: 18.2444 - mae: 18.2444\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 536us/step - loss: 15.0710 - mae: 15.0710\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 756us/step - loss: 14.6102 - mae: 14.6102\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 549us/step - loss: 23.3422 - mae: 23.3422\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 13.3007 - mae: 13.3007\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 605us/step - loss: 9.8125 - mae: 9.8125\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 848us/step - loss: 12.5949 - mae: 12.5949\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 5.3381 - mae: 5.3381\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 772us/step - loss: 14.6967 - mae: 14.6967\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 753us/step - loss: 33.5421 - mae: 33.5421\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 662us/step - loss: 13.8882 - mae: 13.8882\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 538us/step - loss: 10.9915 - mae: 10.9915\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 600us/step - loss: 14.9440 - mae: 14.9440\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 682us/step - loss: 16.9904 - mae: 16.9904\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 16.1796 - mae: 16.1796\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 744us/step - loss: 16.4963 - mae: 16.4963\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 9.9385 - mae: 9.9385\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 631us/step - loss: 17.8344 - mae: 17.8344\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 748us/step - loss: 15.4551 - mae: 15.4551\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 761us/step - loss: 20.8800 - mae: 20.8800\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 579us/step - loss: 20.4230 - mae: 20.4230\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 869us/step - loss: 15.0821 - mae: 15.0821\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 6.9638 - mae: 6.9638\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.7335 - mae: 15.7335\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 543us/step - loss: 6.6860 - mae: 6.6860\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 784us/step - loss: 8.5997 - mae: 8.5997\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 934us/step - loss: 7.7627 - mae: 7.7627\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.6569 - mae: 15.6569\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 590us/step - loss: 9.0050 - mae: 9.0050\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 823us/step - loss: 13.4260 - mae: 13.4260\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 654us/step - loss: 8.8946 - mae: 8.8946\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.3153 - mae: 19.3153\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 681us/step - loss: 13.8818 - mae: 13.8818\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 721us/step - loss: 14.5321 - mae: 14.5321\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 615us/step - loss: 15.6703 - mae: 15.6703\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 916us/step - loss: 17.5037 - mae: 17.5037\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 13.0712 - mae: 13.0712\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 826us/step - loss: 14.4181 - mae: 14.4181\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.8125 - mae: 27.8125\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 807us/step - loss: 7.4997 - mae: 7.4997\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 608us/step - loss: 38.2311 - mae: 38.2311\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 645us/step - loss: 23.1250 - mae: 23.1250\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 817us/step - loss: 7.2885 - mae: 7.2885\n",
      "Epoch 255/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 572us/step - loss: 24.6329 - mae: 24.6329\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 626us/step - loss: 12.3926 - mae: 12.3926\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 758us/step - loss: 10.5619 - mae: 10.5619\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 554us/step - loss: 14.1874 - mae: 14.1874\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 788us/step - loss: 11.2483 - mae: 11.2483\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 31.6073 - mae: 31.6073\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 891us/step - loss: 11.1647 - mae: 11.1647\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0211 - mae: 10.0211\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 550us/step - loss: 8.9364 - mae: 8.9364\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 538us/step - loss: 21.5051 - mae: 21.5051\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 939us/step - loss: 11.4388 - mae: 11.4388\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 628us/step - loss: 13.2732 - mae: 13.2732\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 765us/step - loss: 11.0679 - mae: 11.0679\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 535us/step - loss: 21.7243 - mae: 21.7243\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 810us/step - loss: 32.8943 - mae: 32.8943\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 800us/step - loss: 9.7244 - mae: 9.7244\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 744us/step - loss: 7.7083 - mae: 7.7083\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 590us/step - loss: 28.5122 - mae: 28.5122\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 7.3716 - mae: 7.3716\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 608us/step - loss: 6.3251 - mae: 6.3251\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 897us/step - loss: 37.1297 - mae: 37.1297\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 752us/step - loss: 8.2789 - mae: 8.2789\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 830us/step - loss: 27.9193 - mae: 27.9193\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 770us/step - loss: 10.6191 - mae: 10.6191\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 887us/step - loss: 16.0634 - mae: 16.0634\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 700us/step - loss: 21.1471 - mae: 21.1471\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 24.0138 - mae: 24.0138\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 641us/step - loss: 8.2965 - mae: 8.2965\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 756us/step - loss: 9.0396 - mae: 9.0396\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 641us/step - loss: 22.9563 - mae: 22.9563\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 606us/step - loss: 11.8074 - mae: 11.8074\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 800us/step - loss: 6.7302 - mae: 6.7302\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 811us/step - loss: 20.9250 - mae: 20.9250\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 11.1831 - mae: 11.1831\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 621us/step - loss: 12.4231 - mae: 12.4231\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 16.9585 - mae: 16.9585\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 526us/step - loss: 17.3575 - mae: 17.3575\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 11.4583 - mae: 11.4583\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 14.2736 - mae: 14.2736\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.2014 - mae: 21.2014\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 15.7388 - mae: 15.7388\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 575us/step - loss: 5.8778 - mae: 5.8778\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 614us/step - loss: 11.8173 - mae: 11.8173\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.6543 - mae: 23.6543\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 627us/step - loss: 16.6268 - mae: 16.6268\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 591us/step - loss: 6.7597 - mae: 6.7597\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 522us/step - loss: 23.8666 - mae: 23.8666\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 7.9939 - mae: 7.9939\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 570us/step - loss: 20.3932 - mae: 20.3932\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 588us/step - loss: 13.1548 - mae: 13.1548\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 551us/step - loss: 6.9164 - mae: 6.9164\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 625us/step - loss: 18.5246 - mae: 18.5246\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 9.6488 - mae: 9.6488\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 547us/step - loss: 20.2437 - mae: 20.2437\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 532us/step - loss: 14.2436 - mae: 14.2436\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 5.0939 - mae: 5.0939\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8236 - mae: 13.8236\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 30.3968 - mae: 30.3968\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 537us/step - loss: 6.9062 - mae: 6.9062\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 767us/step - loss: 11.0953 - mae: 11.0953\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 611us/step - loss: 23.3515 - mae: 23.3515\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 14.7972 - mae: 14.7972\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 587us/step - loss: 20.4823 - mae: 20.4823\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 8.6400 - mae: 8.6400\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 873us/step - loss: 15.1289 - mae: 15.1289\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 777us/step - loss: 8.2760 - mae: 8.2760\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 712us/step - loss: 14.5342 - mae: 14.5342\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 757us/step - loss: 12.8454 - mae: 12.8454\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 853us/step - loss: 19.1456 - mae: 19.1456\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 16.8996 - mae: 16.8996\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 9.3144 - mae: 9.3144\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 622us/step - loss: 19.9843 - mae: 19.9843\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.9432 - mae: 27.9432\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 11.7415 - mae: 11.7415\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 792us/step - loss: 16.4271 - mae: 16.4271\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 767us/step - loss: 7.2799 - mae: 7.2799\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 799us/step - loss: 22.4571 - mae: 22.4571\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 13.2636 - mae: 13.2636\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0916 - mae: 10.0916\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 813us/step - loss: 6.5669 - mae: 6.5669\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 841us/step - loss: 6.2470 - mae: 6.2470\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 34.4212 - mae: 34.4212\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 687us/step - loss: 26.8587 - mae: 26.8587\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 13.9373 - mae: 13.9373\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 842us/step - loss: 11.4885 - mae: 11.4885\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 8.8255 - mae: 8.8255\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 773us/step - loss: 23.4821 - mae: 23.4821\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 13.8435 - mae: 13.8435\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 525us/step - loss: 14.8451 - mae: 14.8451\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3831 - mae: 13.3831\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 628us/step - loss: 31.0341 - mae: 31.0341\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 610us/step - loss: 10.7022 - mae: 10.7022\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 647us/step - loss: 25.7375 - mae: 25.7375\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 818us/step - loss: 12.8577 - mae: 12.8577\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 604us/step - loss: 13.1612 - mae: 13.1612\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 15.4345 - mae: 15.4345\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 707us/step - loss: 32.9639 - mae: 32.9639\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 695us/step - loss: 14.2023 - mae: 14.2023\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 662us/step - loss: 15.9187 - mae: 15.9187\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 788us/step - loss: 19.0860 - mae: 19.0860\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 34.1239 - mae: 34.1239\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 563us/step - loss: 7.6804 - mae: 7.6804\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 749us/step - loss: 25.2320 - mae: 25.2320\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 23.6894 - mae: 23.689 - 0s 2ms/step - loss: 22.6795 - mae: 22.6795\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 623us/step - loss: 8.8755 - mae: 8.8755\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 728us/step - loss: 21.4713 - mae: 21.4713\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 604us/step - loss: 20.6071 - mae: 20.6071\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 495us/step - loss: 7.0605 - mae: 7.0605\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 609us/step - loss: 25.8100 - mae: 25.8100\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 867us/step - loss: 32.2220 - mae: 32.2220\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 514us/step - loss: 10.0181 - mae: 10.0181\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 9.6717 - mae: 9.6717\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 741us/step - loss: 30.4192 - mae: 30.4192\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 812us/step - loss: 10.5041 - mae: 10.5041\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9930 - mae: 14.9930\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 14.6598 - mae: 14.6598\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 674us/step - loss: 23.3710 - mae: 23.3710\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 760us/step - loss: 13.0958 - mae: 13.0958\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 9.2519 - mae: 9.2519\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 532us/step - loss: 9.6687 - mae: 9.6687\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 618us/step - loss: 13.0080 - mae: 13.0080\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 836us/step - loss: 14.8908 - mae: 14.8908\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 768us/step - loss: 14.7964 - mae: 14.7964\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 16.2778 - mae: 16.2778\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 651us/step - loss: 20.8384 - mae: 20.8384\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 753us/step - loss: 33.5105 - mae: 33.5105\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 778us/step - loss: 8.2104 - mae: 8.2104\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 525us/step - loss: 13.0814 - mae: 13.0814\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 561us/step - loss: 8.4085 - mae: 8.4085\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 839us/step - loss: 7.1192 - mae: 7.1192\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 949us/step - loss: 10.9433 - mae: 10.9433\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 634us/step - loss: 19.7756 - mae: 19.7756\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 543us/step - loss: 24.8391 - mae: 24.8391\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 556us/step - loss: 8.7316 - mae: 8.7316\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 5.9451 - mae: 5.9451\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 780us/step - loss: 24.4137 - mae: 24.4137\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.9717 - mae: 5.9717\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 756us/step - loss: 16.1533 - mae: 16.1533\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.4943 - mae: 6.4943\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 562us/step - loss: 12.5799 - mae: 12.5799\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 12.4555 - mae: 12.4555\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 785us/step - loss: 7.3614 - mae: 7.3614\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 7.6134 - mae: 7.6134\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 766us/step - loss: 20.4175 - mae: 20.4175\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 781us/step - loss: 5.8943 - mae: 5.8943\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 944us/step - loss: 24.5848 - mae: 24.5848\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.2414 - mae: 13.2414\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 859us/step - loss: 8.3801 - mae: 8.3801\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 855us/step - loss: 10.2381 - mae: 10.2381\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 858us/step - loss: 9.7887 - mae: 9.7887\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.8975 - mae: 6.8975\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 758us/step - loss: 20.2720 - mae: 20.2720\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 766us/step - loss: 9.6436 - mae: 9.6436\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 775us/step - loss: 21.1894 - mae: 21.1894\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 787us/step - loss: 29.9940 - mae: 29.9940\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 676us/step - loss: 9.9040 - mae: 9.9040\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 576us/step - loss: 14.7625 - mae: 14.7625\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 875us/step - loss: 21.5493 - mae: 21.5493\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.1419 - mae: 13.1419\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 733us/step - loss: 8.2780 - mae: 8.2780\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 11.6947 - mae: 11.6947\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 738us/step - loss: 25.6144 - mae: 25.6144\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.7584 - mae: 15.7584\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 555us/step - loss: 12.5770 - mae: 12.5770\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 617us/step - loss: 15.7276 - mae: 15.7276\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 616us/step - loss: 24.4270 - mae: 24.4270\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 777us/step - loss: 18.2785 - mae: 18.2785\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 8.6571 - mae: 8.6571\n",
      "Epoch 423/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 805us/step - loss: 24.6381 - mae: 24.6381\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 775us/step - loss: 16.8746 - mae: 16.8746\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 7.3507 - mae: 7.3507\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.0621 - mae: 21.0621\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 765us/step - loss: 6.5274 - mae: 6.5274\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 583us/step - loss: 13.4887 - mae: 13.4887\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 804us/step - loss: 11.2121 - mae: 11.2121\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 663us/step - loss: 12.1138 - mae: 12.1138\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1176 - mae: 9.1176\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 15.6471 - mae: 15.6471\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 781us/step - loss: 11.9610 - mae: 11.9610\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 754us/step - loss: 30.4708 - mae: 30.4708\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5323 - mae: 10.5323\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 582us/step - loss: 28.9655 - mae: 28.9655\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 8.6946 - mae: 8.6946\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 12.7553 - mae: 12.7553\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 754us/step - loss: 33.7270 - mae: 33.7270\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 765us/step - loss: 15.1735 - mae: 15.1735\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 17.5385 - mae: 17.5385\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 608us/step - loss: 22.4291 - mae: 22.4291\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 882us/step - loss: 23.2869 - mae: 23.2869\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 790us/step - loss: 10.7593 - mae: 10.7593\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 819us/step - loss: 14.9876 - mae: 14.9876\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 563us/step - loss: 18.1002 - mae: 18.1002\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 808us/step - loss: 5.3366 - mae: 5.3366\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 10.1456 - mae: 10.1456\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.0793 - mae: 14.0793\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 828us/step - loss: 16.8498 - mae: 16.8498\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 14.3229 - mae: 14.3229\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 929us/step - loss: 30.6834 - mae: 30.6834\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 542us/step - loss: 8.4009 - mae: 8.4009\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 550us/step - loss: 27.5900 - mae: 27.5900\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 718us/step - loss: 10.0908 - mae: 10.0908\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.5462 - mae: 14.5462\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 657us/step - loss: 17.6970 - mae: 17.6970\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 622us/step - loss: 14.0113 - mae: 14.0113\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 519us/step - loss: 25.8950 - mae: 25.8950\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 848us/step - loss: 15.0604 - mae: 15.0604\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 665us/step - loss: 11.9197 - mae: 11.9197\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 612us/step - loss: 13.2685 - mae: 13.2685\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 571us/step - loss: 29.4505 - mae: 29.4505\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.2600 - mae: 3.2600\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 40.3677 - mae: 40.3677\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 788us/step - loss: 18.4317 - mae: 18.4317\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 538us/step - loss: 8.5989 - mae: 8.5989\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 795us/step - loss: 6.6506 - mae: 6.6506\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 794us/step - loss: 29.5241 - mae: 29.5241\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 521us/step - loss: 15.3652 - mae: 15.3652\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2781 - mae: 12.2781\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 783us/step - loss: 15.4595 - mae: 15.4595\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 772us/step - loss: 19.4330 - mae: 19.4330\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 578us/step - loss: 38.6142 - mae: 38.6142\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5886 - mae: 15.5886\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 886us/step - loss: 13.5059 - mae: 13.5059\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 972us/step - loss: 29.8805 - mae: 29.8805\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 638us/step - loss: 4.8553 - mae: 4.8553\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 13.0409 - mae: 13.0409\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 608us/step - loss: 19.2275 - mae: 19.2275\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 13.0147 - mae: 13.0147\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 764us/step - loss: 6.8125 - mae: 6.8125\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.1679 - mae: 13.1679\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 791us/step - loss: 14.0387 - mae: 14.0387\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 746us/step - loss: 9.3098 - mae: 9.3098\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 18.4934 - mae: 18.4934\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 6.2320 - mae: 6.2320\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.5233 - mae: 29.5233\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 12.7531 - mae: 12.7531\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 603us/step - loss: 13.1513 - mae: 13.1513\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 875us/step - loss: 24.4569 - mae: 24.4569\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 598us/step - loss: 18.4078 - mae: 18.4078\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.7297 - mae: 4.7297\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 613us/step - loss: 11.7971 - mae: 11.7971\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 644us/step - loss: 13.7933 - mae: 13.7933\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 749us/step - loss: 12.9635 - mae: 12.9635\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 745us/step - loss: 18.1394 - mae: 18.1394\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 684us/step - loss: 22.3911 - mae: 22.3911\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2324 - mae: 8.2324\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.1702 - mae: 14.1702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224e5c2b100>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model3 with 2 layers und 500 epochs:\n",
    "tf.random.set_seed(42)\n",
    "# create a model:\n",
    "model_3=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "#compile the model:\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=['mae'])\n",
    "#fitting the model_3\n",
    "model_3.fit(x_train,y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f5c4a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224E5C54C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_3=model_3.predict(x_test)\n",
    "plot_predictions(predictions=y_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "29bf9448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.37856\n",
      "3608.4526\n"
     ]
    }
   ],
   "source": [
    "mae_3=mae(y_test,y_pred_3)\n",
    "mse_3=mse(y_test,y_pred_3)\n",
    "print(mae_3)\n",
    "print(mse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f490316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>1.939358</td>\n",
       "      <td>5.590437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>20.312002</td>\n",
       "      <td>415.427155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>59.378559</td>\n",
       "      <td>3608.452637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1   1.939358     5.590437\n",
       "1  model_2  20.312002   415.427155\n",
       "2  model_3  59.378559  3608.452637"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the result of our experiment:\n",
    "# let compare our model result using pandas:\n",
    "import pandas as pd\n",
    "model_result=[['model_1',mae_1,mse_1],\n",
    "             ['model_2',mae_2,mse_2],\n",
    "             ['model_3',mae_3,mse_3]]\n",
    "all_result=pd.DataFrame(model_result,columns=['model','mae','mse'])\n",
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5f096724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# looks like model_1 performed the best\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fd160",
   "metadata": {},
   "source": [
    "## Tracking the experiment:\n",
    "* Tensorborad - a component of the tensorflow library to help track modelling experiment.\n",
    "* weights & biases - a tool for tracking all of kinds of machine learning experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70085ab",
   "metadata": {},
   "source": [
    "##### saving our model allow us to use them outside of notebook such as as a web application or a mobile app.\n",
    "* there are two main formats we can save our model's too\n",
    "    1. the saveModel format\n",
    "    2. the HDF5 format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3a323717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_saveModelformat\\assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save(\"best_model_saveModelformat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0ebd391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model using HDF5 format\n",
    "model_1.save('best_model_HDF5_format.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7aa270db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading  the saved model\n",
    "loaded_saved_modelformat=tf.keras.models.load_model('best_model_saveModelformat')\n",
    "loaded_saved_modelformat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6c8e93c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f48de57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprare  model_2 prediction with loaded_saved_modelformat predictions\n",
    "model_1_pred=model_1.predict(x_test)\n",
    "loaded_saved_modelformat_pred=loaded_saved_modelformat.predict(x_test)\n",
    "model_1_pred=loaded_saved_modelformat_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "abba4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the mean square error for  model_1_pred and loaded_saved_modelformat_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4aea4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_test,model_1_pred)==mae(y_test,loaded_saved_modelformat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc7cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
